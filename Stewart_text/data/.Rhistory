install.packages(as.character(pcl))
for (pcl in a) {print pcl
for (pcl in a) {
print(pcl)
install.packages(as.character(pcl))
}
for (pcl in a) {
print(as.character(pcl))
install.packages(as.character(pcl))
}
for (pcl in a$AER) {
print(as.character(pcl))
install.packages(as.character(pcl))
}
install.packages(as.character(pcl))
library(stm)
library(mallet)
library(rJava)
library(stm)
library(devtools)
library(dplyr)
install.packages("stm")
install.packages("dplyr")
install.packages("ggplot2")
library("XML")
library("tm")
install.packages("tm")
source("/Users/clarkbernier/Downloads/muxViz-master/muxVizGUI.R")
install.packages("servr")
install.packages("shiny")
install.packages("shiny")
source("/Users/clarkbernier/Downloads/muxViz-master/muxVizGUI.R")
install.packages("shiny")
source("/Users/clarkbernier/Downloads/muxViz-master/muxVizGUI.R")
install.packages("shiny")
source("/Users/clarkbernier/Downloads/muxViz-master/muxVizGUI.R")
install.packages("shiny")
a <- c(1,2,3,4,1,3,2)
library(ggplot2)
?geom_line
?geom_ablineline
?geom_abline
?cvfold
library("robustbase")
data("coleman")
set.seed(1234) # set seed for reproducibility
# set up folds for cross-validation
folds <- cvFolds(nrow(coleman), K = 5, R = 10)
library(cvTools)
install.packages("cvtoold")
install.packages("cvtools")
install.packages("cvTools")
library(cvTools)
folds <- cvFolds(nrow(coleman), K = 5, R = 10)
fitLm <- lm(Y ~ ., data = coleman)
cvFitLm <- cvLm(fitLm, cost = rtmspe,
folds = folds, trim = 0.1)
# perform cross-validation for an MM regression model
fitLmrob <- lmrob(Y ~ ., data = coleman)
cvFitLmrob <- cvLmrob(fitLmrob, cost = rtmspe,
folds = folds, trim = 0.1)
# perform cross-validation for an LTS regression model
fitLts <- ltsReg(Y ~ ., data = coleman)
cvFitLts <- cvLts(fitLts, cost = rtmspe,
folds = folds, trim = 0.1)
cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
table(predicted.rating, test.rating)
We use Eisenstein and Xing's (2010) poliblog5k sample of 5000 political blog posts from 2008 that are encoded as **conservative** or **liberal**.  In order to demonstrate the full work flow, we're going to pretend that we've only encoded 1000 (20%) of the blogs that we can use to train our model and we'll have to use predicted values for the other 5000.  Why 20%?  Because I tried with 10% and the algorithm wouldn't converge--so I "coded" an expanded sample of documents.
library(stm)
# view ?poliblog5k for the full description of the dataset
data(poliblog5k)
# it has three pieces:
#    poliblog5k.docs -- the blog texts in the text-as-numbers format used by lda and stm
#    poliblog5k.voc -- the vocabulary of the texts in the format used by lda and stm
#    poliblog5k.meta -- the blog post metadata:
head(poliblog5k.meta)
# reproducible numbers are our friend
set.seed(122)
# split into "encoded" and "unencoded" sets
sample.index <- sample(1:5000, 1000)
encod.docs <- poliblog5k.docs[sample.index]
unencoded.docs <- poliblog5k.docs[-sample.index]
encod.meta <- poliblog5k.meta[sample.index, ]
unencoded.meta <- poliblog5k.meta[-sample.index,]
# but we'll pretend like we don't have unencoded.meta$rating
library(textir)
data(we8there)
# we8thereRatings: 5 outcome variables of user restaurant ratings
# we8thereCounts: sparse matrix document-term representation of the review text
str(we8thereCounts)
encod.dtm <- convertCorpus(encod.docs, poliblog5k.voc, type="Matrix")
mnir.fit <- mnlm(NULL, # single-threaded for now
as.numeric(encod.meta$rating), # the outcome of interest
encod.dtm, # the document-term counts
bins = NULL # the default value, tells it not to use each word
# rather than collapse dimensions
)
coefs <- coef(mnir.fit)
# most conservative words (lower "rating")
coefs[2, order(coefs[2, ])[1:10]]
# most liberal words (higher "rating"")
coefs[2, order(-coefs[2, ])[1:10]]
forward.fit <- lm(as.numeric(encod.meta$rating) ~ z)
summary(forward.fit)
plot(forward.fit$fitted ~ encod.meta$rating)
# let's say any prediction <1.5 is "Conservative" and "Liberal" otherwise
predicted.rating <- ifelse(forward.fit$fitted < 1.5, "Conservative", "Liberal")
table(predicted.rating, encod.meta$rating)
train.share <- 0.8
train.index <- sample(1:nrow(encod.dtm), train.share * nrow(encod.dtm))
# document term matrices
train.dtm <- encod.dtm[train.index, ]
test.dtm <- encod.dtm[-train.index, ]
# conservative / liberal ratings
train.rating <- encod.meta[train.index, "rating"]
test.rating <- encod.meta[-train.index, "rating"]
fullMnir <- function(rating, dtm) {
mnir.fit <- mnlm(NULL, # single-threaded for now
as.numeric(rating), # the outcome of interest
dtm, # the document-term counts
bins = NULL # the default value, tells it not to use each word
# rather than collapse dimensions
)
coefs <- coef(mnir.fit)
z <- srproj(coefs, dtm)
# we need to pack this in data.frame with set names or later predict will get angry
df <- data.frame(rating=as.numeric(rating),
z1=z[,1],
zm=z[,2]
)
forward.fit <- lm(as.numeric(rating) ~ ., data=df)
# return the fits of BOTH regression, as we need both to predict the test set
return (list(mnir.fit=mnir.fit, forward.fit=forward.fit))
}
predictTestMnir <- function(fits, test.dtm) {
# project our test set into the model's z-space
coefs <- coef(fits$mnir.fit)
# we have the do the same data.frame and names trick to the test zs to avoid predict's wrath
test.z <- data.frame(srproj(coefs, test.dtm))
names(test.z) <- c("z1","zm")
return(predict(fits$forward.fit, newdata=test.z))
}
fits <- fullMnir(train.rating, train.dtm)
test.predictions <- predictTestMnir(fits, test.dtm)
plot(test.predictions~ test.rating)
# let's say any prediction <1.5 is "Conservative" and "Liberal" otherwise
predicted.rating <- ifelse(test.predictions < 1.5, "Conservative", "Liberal")
table(predicted.rating, test.rating)
coefs <- coef(mnir.fit)
z <- srproj(coefs, encod.dtm)
forward.fit <- lm(as.numeric(encod.meta$rating) ~ z)
summary(forward.fit)
plot(forward.fit$fitted ~ encod.meta$rating)
# let's say any prediction <1.5 is "Conservative" and "Liberal" otherwise
predicted.rating <- ifelse(forward.fit$fitted < 1.5, "Conservative", "Liberal")
table(predicted.rating, encod.meta$rating)
table(predicted.rating, encod.meta$rating)
table(predicted.rating, encod.meta$rating)
sum(diag(results)) / sum(results)
results <- table(predicted.rating, encod.meta$rating)
results
sum(diag(results)) / sum(results)
results <- table(predicted.rating, test.rating)
results
fits <- fullMnir(train.rating, train.dtm)
test.predictions <- predictTestMnir(fits, test.dtm)
plot(test.predictions~ test.rating)
# let's say any prediction <1.5 is "Conservative" and "Liberal" otherwise
predicted.rating <- ifelse(test.predictions < 1.5, "Conservative", "Liberal")
results <- table(predicted.rating, test.rating)
results
# and accuracy
sum(diag(results)) / sum(results)
a <- c(.2,.3,.25)
a <- c(.2,.3,.25,.1)
mean(a)
1-mean(a)
mean(1-a)
?predict
?cvFolds
folds <- cvFolds(nrow(encod.docs), K = 5)
nrow(encod.docs)
nrow(encod.dtm)
folds <- cvFolds(nrow(encod.dtm), K = 5)
folds <- cvFolds(nrow(encod.dtm), K = 5)
accuracies <- rep(NA, length(folds))
for (i in 1:length(folds)) {
fold <- folds[i]
# the training set is everything except the current fold
train.dtm <- encod.dtm[-fold, ]
# and we use the current fold as a test set
test.dtm <- encod.dtm[fold, ]
# conservative / liberal ratings
train.rating <- encod.meta[-fold, "rating"]
test.rating <- encod.meta[fold, "rating"]
# fitting / predicting is the same as above
fits <- fullMnir(train.rating, train.dtm)
test.predictions <- predictTestMnir(fits, test.dtm)
# and finally, we calculate the accuracy with which we've predicted this test fold
results <- table(predicted.rating, test.rating)
accuracies[i] <- sum(diag(results)) / sum(results)
}
str(folds)
folds$subsets[folds$which==1,1]
folds <- cvFolds(nrow(encod.dtm), K = 10)
str(folds) # $subsets has the randomized indices and $which is the partition index.
accuracies <- rep(NA, length(folds))
for (i in 1:folds$K) {
fold <- folds$subsets[folds$which==i, 1]
# the training set is everything except the current fold
train.dtm <- encod.dtm[-fold, ]
# and we use the current fold as a test set
test.dtm <- encod.dtm[fold, ]
# conservative / liberal ratings
train.rating <- encod.meta[-fold, "rating"]
test.rating <- encod.meta[fold, "rating"]
# fitting / predicting is the same as above
fits <- fullMnir(train.rating, train.dtm)
test.predictions <- predictTestMnir(fits, test.dtm)
# and finally, we calculate the accuracy with which we've predicted this test fold
results <- table(predicted.rating, test.rating)
accuracies[i] <- sum(diag(results)) / sum(results)
}
predicted.rating <- ifelse(test.predictions < 1.5, "Conservative", "Liberal")
results <- table(predicted.rating, test.rating)
results
folds <- cvFolds(nrow(encod.dtm), K = 10)
str(folds) # $subsets has the randomized indices and $which is the partition index.
accuracies <- rep(NA, length(folds))
for (i in 1:folds$K) {
fold <- folds$subsets[folds$which==i, 1]
# the training set is everything except the current fold
train.dtm <- encod.dtm[-fold, ]
# and we use the current fold as a test set
test.dtm <- encod.dtm[fold, ]
# conservative / liberal ratings
train.rating <- encod.meta[-fold, "rating"]
test.rating <- encod.meta[fold, "rating"]
# fitting / predicting is the same as above
fits <- fullMnir(train.rating, train.dtm)
test.predictions <- predictTestMnir(fits, test.dtm)
# and finally, we calculate the accuracy with which we've predicted this test fold
predicted.rating <- ifelse(test.predictions < 1.5, "Conservative", "Liberal")
results <- table(predicted.rating, test.rating)
accuracies[i] <- sum(diag(results)) / sum(results)
}
accuracies
mean(accuracies)
fits <- fullMnir(encod.meta$rating, encod.dtm)
unencod.dtm <- convertCorpus(unencod.docs, poliblog5k.voc, type="Matrix")
unencod.dtm <- convertCorpus(unencoded.docs, poliblog5k.voc, type="Matrix")
predicted.ratings <- predictTestMnir(fits, unencod.dtm)
predicted.politics <- ifelse(predicted.ratings < 1.5, "Conservative", "Liberal")
full.ratings <- rbind(predicted.politics, encod.meta$ratings)
encod.meta$ratings
encod.meta$rating
full.ratings <- rbind(predicted.politics, encod.meta$rating)
full.ratings <- c(predicted.politics, encod.meta$rating)
full.ratings <- as.factor(c(predicted.politics, encod.meta$rating))
full.ratings <- c(as.factor(predicted.politics), encod.meta$rating)
new.data <- rbind(unencoded.meta, encod.meta)
new.data <- rbind(unencoded.meta, encod.meta)
new.data$rating = c(as.factor(predicted.politics), encod.meta$rating)
new.data$predicted = c(rep(1, 4000), rep(0,1000))
c(as.factor(predicted.politics), encod.meta$rating)
encod.meta$rating
as.factor(predicted.politics)
encod.meta$rating
new.data$rating = as.factor(c(as.factor(predicted.politics), encod.meta$rating))
new.data$rating = c(predicted.politics, as.character(encod.meta$rating))
new.data$rating <- as.facotr(new.data$rating)
new.data$rating <- as.factor(new.data$rating)
new.data$predicted = c(rep(1, 4000), rep(0,1000))
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot(data=new.data, aes(x=day, y=posts, color=rating)) + geom_line()
library(dplyr)
library(tidyr)
library(ggplot2)
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot(data=new.data, aes(x=day, y=posts, color=rating)) + geom_line()
new.data %>%
group_by(day, rating) %>%
summarize(posts=n())
?geom_line
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot(data=new.data, aes(x=day, y=posts)) + geom_line()
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_line(aes(x=day, y=posts))
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=rating))
new.data %>%
filter(predicted=0) %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=rating))
new.data %>%
filter(predicted==0) %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=rating))
?geom_smooth
new.data$old.rating <- new.data$rating
new.data <- rbind(unencoded.meta, encod.meta)
new.data$old.rating <- new.data$rating
new.data$rating = c(predicted.politics, as.character(encod.meta$rating))
new.data$rating <- as.factor(new.data$rating)
# and include a flag for whether the rating value is predicted
new.data$predicted = c(rep(1, 4000), rep(0,1000))
new.data %>%
group_by(day, old.rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=old.rating))
new.data <- rbind(unencoded.meta, encod.meta)
new.data$old.rating <- new.data$rating
new.data$rating = c(predicted.politics, as.character(encod.meta$rating))
new.data$rating <- as.factor(new.data$rating)
# and include a flag for whether the rating value is predicted
new.data$predicted = c(rep(1, 4000), rep(0,1000))
new.data %>%
group_by(day, old.rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=old.rating))
new.data %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=rating))
new.data %>%
filter(predicted==0) %>%
group_by(day, rating) %>%
summarize(posts=n()) %>%
ggplot() + geom_smooth(aes(x=day, y=posts, colour=rating))
library(dplyr)
library(tidyr)
source('~/.active-rstudio-document', echo=TRUE)
library(stringr)
library(ggplot2)
getJournalCites <- function(file.loc) {
#
col.names <- unlist(read.delim(file.loc, header=F, stringsAsFactors = F, nrow=1))
cites <- read.delim(file.loc, header=F, stringsAsFactors = F, skip=1)
# remove the trailing column, and any without abstracts
cites <- select(cites, -14)
names(cites) <- col.names
cites <- filter(cites, nchar(abstract)>0)
cites$year <- format(as.Date(cites$pubdate), "%Y")
return(cites)
}
getJournalCites <- function(file.loc) {
#
col.names <- unlist(read.delim(file.loc, header=F, stringsAsFactors = F, nrow=1))
cites <- read.delim(file.loc, header=F, stringsAsFactors = F, skip=1)
# remove the trailing column, and any without abstracts
cites <- select(cites, -14)
names(cites) <- col.names
cites <- filter(cites, nchar(abstract)>0)
cites$year <- format(as.Date(cites$pubdate), "%Y")
return(cites)
}
ajs.cites <- getJournalCites("../data/ajs_1997_2013/citations.tsv")
setwd("/Users/clarkbernier/Dropbox/Soc592Text/labs/data")
ajs.cites <- getJournalCites("../data/ajs_1997_2013/citations.tsv")
View(ajs.cites)
ajs.cites.2 <- getJournalCites("../data/ajs_75_96/citations.tsv")
asr.cites <- getJournalCites("../data/asr_1997_2013/citations.tsv")
asr.cites.2 <- getJournalCites("../data/asr_85_96/citations.tsv")
asr.cites.3 <- getJournalCites("../data/asr_75_84/citations.tsv")
source('~/.active-rstudio-document', echo=TRUE)
cites <- rbind(ajs.cites, ajs.cites.2, asr.cites, asr.cites.2, asr.cites.3)
View(cites)
asr.cites.3 <- getJournalCites("../ddata/asr_75_84/citations.tsv")
library(quanteda)
?corpus
version()
Version(
)
corpus <- corpus(cites$abstract,
docnames=cites$id,
docvars=select(cites, journaltitle, year, author, title))
doc.features <- dfm(corpus, ignoredFeatures=stopwords("english"), stem=T)
stopwords("english")
stopwords("german")
doc.features <- trim(doc.features, minDoc=0.01, verbose=T)
doc.features$vocab
vocab(doc.features)
colnames(doc.features)
doc.features$features
plot(doc.features, max.words = 100)
warnings()
kmeans.results.10 <- kmeans(doc.features, centers = 10, nstart = 10)
set.seed(12345)
kmeans.results.10 <- kmeans(doc.features, centers = 10, nstart = 10)
kmeans.results.5 <- kmeans(doc.features, centers = 5, nstart = 10)
kmeans.results.10a <- kmeans(doc.features, centers = 10, nstart = 10)
kmeans.results.10b <- kmeans(doc.features, centers = 10, nstart = 10)
head(kmeans.results.10$cluster)
str(kmeans.results.10)
doc.indexes <- kmeans.results.10$cluster
plot(doc.features[doc.indexes==1, ], max.words = 100)
plot(doc.features[doc.indexes==5, ], max.words = 100)
plot(doc.features[doc.indexes==6, ], max.words = 100)
cluster.terms <- colSums(dfm[clust.vect, ])
clusterLabels(doc.features, kmeans.results.10, 10)
clusterFightinWords <- function(dfm, clust.vect, alpha.0=500) {
# we need to get the overall corpus word distribution and the cluster-specific words dists
# y_{kw} in Monroe et al.
overall.terms <- colSums(dfm)
# n and n_k in Monroe et al.
n <- sum(overall.terms)
# alpha_{kw} in Monroe et al.
prior.terms <- overall.terms / n * alpha.0
# y_{kw}(i) in Monroe et al.
cluster.terms <- colSums(dfm[clust.vect, ])
# n_k(i) in Monroe et al.
cluster.n <- sum(cluster.terms)
cluster.term.odds <-
(cluster.terms + prior.terms) /
(cluster.n + alpha.0 - cluster.terms - prior.terms)
overall.term.odds <-
(overall.terms + prior.terms) /
(n + alpha.0 - overall.terms - prior.terms)
# usually, we'd hate to blindly log something, but as long as we have a non-zero prior,
# these will both be non-zero.
log.odds <- log(cluster.term.odds) - log(overall.term.odds)
variance <- 1/(cluster.terms + prior.terms) + 1/(overall.terms + prior.terms)
# return the variance weighted log-odds for each term
return(log.odds / sqrt(variance))
}
```
We also need a function, **clusterLabels** that can call **clusterFightingWords** for each cluster and package the results into a tidy set of labels.
```{r}
# dfm -- a quanteda document-term object
# results -- a k-means results object
# n.terms -- the number of terms to include in the label
clusterLabels <- function(dfm, results, n.terms=10) {
clusters <- length(results$withinss)
labels <- rep("", clusters)
for (clust.num in 1:clusters) {
clust.vect <- results$cluster==clust.num
terms <- clusterFightinWords(dfm, clust.vect)
terms <- order(terms, decreasing = T)[1:n.terms]
# use the terms as indices on the features list of the dfm
labels[clust.num] <- paste(features(dfm)[terms], collapse=":")
}
return(labels)
}
clusterLabels(doc.features, kmeans.results.10, 10)
clusterLabels(doc.features, kmeans.results.10, 5)
clusterLabels(doc.features, kmeans.results.10, 20)
clusterLabels(doc.features, kmeans.results.10, 10)
clusterLabels(doc.features, kmeans.results.10, 10)
clusterLabels(doc.features, kmeans.results.10a, 10)
clusterLabels(doc.features, kmeans.results.10b, 10)
clusterLabels(doc.features, kmeans.results.10, 10)
labels <- clusterLabels(doc.features, kmeans.results.10, 10)
corpus$documents$cluster <- kmeans.results.10$cluster
printCourpusCluster <- function(corpus, clust.num, num.docs) {
print(labels[clust.num])
cluster.corpus <- subset(corpus, cluster==clust.num)
# sample some docs from the cluster sub corpus
cluster.docs <- sample(cluster.corpus, num.docs)$documents
return(cluster.docs)
}
printCourpusCluster(corpus, 5, num.docs=5)
corpus$documents$cluster <- kmeans.results.10$cluster
labels <- clusterLabels(doc.features, kmeans.results.10, 10)
label.df <- data.frame(cluster=1:length(labels), cluster.name=labels)
corpus$documents %>%
left_join(label.df) %>%
ggplot() +
geom_bar(aes(x=cluster.name, color=journaltitle), position="dodge", width=0.75) +
xlab("Cluster") +
ylab("Number of Articles") +
# the labels are loooonnnngggg, so rotate them 90 degrees
theme(axis.text.x=element_text(angle=90, hjust=1))
corpus$documents$cluster <- kmeans.results.10$cluster
labels <- clusterLabels(doc.features, kmeans.results.10, 5)
# package the labels into a lookup dataframe so it can be merged into the corpus and used in the graph
label.df <- data.frame(cluster=1:length(labels), cluster.name=labels)
corpus$documents %>%
left_join(label.df) %>%
ggplot() +
geom_bar(aes(x=cluster.name, color=journaltitle), position="dodge", width=0.75) +
xlab("Cluster") +
ylab("Number of Articles") +
# the labels are loooonnnngggg, so rotate them 45 degrees
theme(axis.text.x=element_text(angle=45, hjust=1))
```
graph + ylim(0,0.2)
corpus$documents$cluster.5 <- kmeans.results.5$cluster
labels.5 <- clusterLabels(doc.features, kmeans.results.5, 5)
label.df.5 <- data.frame(cluster.5=1:length(labels.5), cluster.name=labels.5)
corpus$documents %>%
left_join(label.df.5) %>%
# add in the total number of annual articles to use as the denominator
group_by(year) %>% mutate(year.articles=n()) %>%
# and the calculate the share of articles per year each cluster has
group_by(year, cluster.name) %>%
summarize(percent.articles = n()/max(year.articles)) %>%
ggplot() +
geom_line(aes(x=as.numeric(year), y=percent.articles, color=cluster.name)) +
xlab("Year") +
ylab("Share of Articles")
